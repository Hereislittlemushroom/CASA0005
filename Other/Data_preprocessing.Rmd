---
title: "Data Preprocessing"
author: "Zeqiang Fang"
date: "1/5/2021"
output: pdf_document
---

## 1. Read data into R

The NCR is a database of publicly-available chargepoints for electric vehicles in the UK established in 2011(,2021). you can access data in this [link](https://www.gov.uk/guidance/find-and-use-data-on-public-electric-vehicle-chargepoints#accessing-data-on-ncv)

Now, let's read origional data in R
```{r}
UK_NCR= read.csv("http://chargepoints.dft.gov.uk/api/retrieve/registry/format/csv") 
# This may take for a while, which depends on the speed of internet

# you can have a overview of this dataset
print("The number of rows is: ")
nrow(UK_NCR)
print("The number of columns is: ")
ncol(UK_NCR)
print("70 of all varriables are:")
UK_NCR %>%
  names() %>%
    head(.,n = 70)
```

Tip: If you cannot successfully read this dataset, you can replace the above link with "https://raw.githubusercontent.com/Hereislittlemushroom/CASA0005_Final_Assessment/main/Dataset/national-charge-point-registry.csv"

## 2. Data Selection

Select the charge points of london area in this UK csv file。
You can utilise `filter` function from `dplyr` package to choose the charge point data in london boroughs
```{r}
London_NCR = UK_NCR %>%
  dplyr::filter(  !is.na(county),
                  county == "London" | 
                  county == "Greater London " | 
                  county == "London Borough of Camden" |
                  county == "London Borough of Ealing" | 
                  county == "London Borough of Greenwich" | 
                  county == "London Borough of Hackney" | 
                  county == "London Borough of Hammersmith and Fulham" | 
                  county == "London Borough of Hounslow" | 
                  county == "London Borough of Islington" | 
                  county == "London Borough of Lambeth" | 
                  county == "London Borough of Richmond upon Thames" | 
                  county == "London Borough of Southwark" |
                  county == "London Borough Of Southwark" |
                  county == "London Borough of Waltham Forest" | 
                  county == "London Borough of Wandsworth")
```

Check if all values in `county` are attributed to "London"
```{r}
isLondon = London_NCR$county %>%
  unique()
isLondon
```

In the next step, you can select the valuable attributes e.g. latitude,longitude.
```{r}
# Tip: the index of data frame starts from 1
# Select the variables by their index
London_NCR = London_NCR %>%
  select(1,4,5,13,14,15,32,35,36,38,54)

# Check the variables we have chosen and the number of rows & cols
London_NCR %>%
  names()
London_NCR %>%
  nrow()
London_NCR %>%
  ncol()
```

## 3. Data Cleaning

Map and visualisation play important roles in spatial analysis. To make a heat map for further research, you need to merge geographic information for each row in charge point dataset in the first place.

To begin with, import "PostcodesioR". This R package offer methods to match
```{r}
install.packages("PostcodesioR")
library(PostcodesioR)
```

Before applying "for-loop" method to fill values in `GSS_CODE` by identifying `postcode`, you can add a new columns called `GSS_CODE` in London_NCR dataset.
```{r}
London_NCR_GSS_Added = London_NCR %>%
  rowwise() %>%
  mutate(GSS_CODE = postcode) %>%
  # Tip: it is essential to transform numerical data into one in character
  mutate(GSS_CODE = as.character(GSS_CODE))

# Pay attention to the for loop in dataframe, it starts from 1

i = 1
for (val in London_NCR_GSS_Added$postcode) {
  try({ temp1 = PostcodesioR::postcode_lookup(val)
        if(!is.null(temp)){
          temp2 = temp1$admin_district_code[1]
          London_NCR_GSS_Added$GSS_CODE[i] = temp2
        }else{
          London_NCR_GSS_Added$GSS_CODE[i] = ""
        }
        i = i+1 }
      ,silent = TRUE)
}

# remove the rows whose value of `GSS_CODE` is empty
# There are limitations in this process because the rows missing `GSS_CODE` cannot be included in the dataset, which can slightly affect the research results 

London_NCR_GSS_Added$GSS_CODE[London_NCR_GSS_Added$GSS_CODE==""] = NA
London_NCR_GSS_Added = London_NCR_GSS_Added %>%
  filter(!is.na(GSS_CODE))
```

Finally, it is of importance to export our prepossessed data into csv file! Now we get the London_NCR_GSS_Added.csv in our "/Dataset" path. 

Also, you can access this prepocessed dataset in github link:
  https://raw.githubusercontent.com/Hereislittlemushroom/CASA0005_Final_Assessment/main/Dataset/London_NCR_GSS_Added.csv

```{r}
# export London_NCR_GSS_Added data frame into .CSV format 
library(here)
write.csv(London_NCR_GSS_Added, here::here("Dataset","London_NCR_GSS_Added.csv"), row.names = FALSE, col.names = TRUE)
# `col.names = TRUE` is important to be writen down
          
```

## Heat Map making 

- there comes a map of London borough in order to draw point in this map after data preparation
```{r}
library(sf)
London_Borough = st_read("/Users/fangzeqiang/Desktop/SDSV/Final/CASA0005_Final_Assessment/Dataset/statistical-gis-boundaries-london/ESRI/London_Borough_Excluding_MHW.shp")
# .shp should be loaded in ESRI folder and path instead of relative path!
# plot(London_Borough)
 plot(st_geometry(London_Borough))
```

- Then read csv in mycsv
```{r}
# library(tidyverse)
mycsv = London_NCR_GSS_Added
```

- In order to make heat mapping, count the frequency of GSS_CODE
```{r}
# mycsv_frequency_by_gsscode
mycsv_fba = mycsv %>%
  group_by(GSS_CODE) %>% # group by GSS_CODE
  summarise(Freq = n())

ncol(mycsv_fba)
nrow(mycsv_fba)
```

- 方法一：全连接
![merge function](https://img-blog.csdn.net/20180304105932852?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbmV3ZWFzdHN1bg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
```{r}
# sample1:  full_join(x,y, by = NULL, copy = FALSE, suffix = c(".x", ".y"), ...)
All_join_London_Borough_Shape = London_Borough %>%
  merge(.,
        mycsv_fba,
        by.x = "GSS_CODE",
        by.y = "GSS_CODE",
        all = TRUE)

# 需要数据处理一下把 Freq变量缺失的改成0

fun1 <- function(x) {
     x[is.na(x)] = 1
     x
}
sapply(All_join_London_Borough_Shape, fun1)

nrow(All_join_London_Borough_Shape)
ncol(All_join_London_Borough_Shape)
All_join_London_Borough_Shape %>%
  names()
```

- 方法二：内连接把London_Borough与mycsv_fba中匹配的数据加入mycsv_fda中Join
```{r}
London_Borough_Shape = London_Borough %>%
  merge(.,
        mycsv_fba,
        by.x = "GSS_CODE",
        by.y = "GSS_CODE")
```

check the new shape
```{r}
London_Borough_Shape%>%
  head(.,n=10)
```

- heat map making preparation
tip: library(tmap) will take a while, maybe 4min
```{r}
library(tmap)
tmap_mode("plot")
```

- fill by frequency 
```{r}
London_Borough_Shape %>%
  qtm(.,fill = "Freq")
```
- fill by frequency_test_1
```{r}
All_join_London_Borough_Shape %>%
  qtm(.,fill = "Freq")
```
![London Borough Names](https://i.pinimg.com/originals/e8/c7/10/e8c71070a42fde7bedaafff87379f251.gif)
After observing the map and borough name


limitation:
Accuracy: divid frequency by county may not be the most effcient way to delivery our idea. Maybe the contiunous heat map based on 4324 project will be a good solution.


## Backup

Let's have a try to manipulate data with R
```{r}
London_NCR = read.csv(here::here("Dataset","london-NCR-edit.csv"),
                      header = TRUE,
                      sep = ",",
                      na = "n/a", #fulfill all the N/A value
                      encoding = "latin1")
```

We can see types of all rows
```{r}
library(tidyr,dplyr,tidyverse)
Datatypelist = London_NCR %>% 
  summarise_all(class) %>%
  pivot_longer(everything(), 
               names_to="All_variables", 
               values_to="Variable_class")

Datatypelist
```

Read london-NCR-edit data in R again!
```{r}
London_NCR = read_csv(here::here("Dataset","london-NCR-edit.csv"),
                       locale = locale(encoding = "latin1"))
```

Overview of london-NCR
```{r}
head(colnames(London_NCR))
```

Take a snapshot of county of data and delete the distinct stuff
```{r}
County_GreaterLondon = London_NCR %>%
  filter(`county` == "Greater London") # similar to filter function in excel
#summary(County_GreaterLondon)
County_GreaterLondon = County_GreaterLondon %>%
  distinct()
#summary(County_GreaterLondon)
```

But there is not all of cols we need. In the next step, we need to select valuable cols to analysis
```{r}
# we can get the index
```

read .gpkg in systems
```{r}
library(sf)
charging_points = st_read("/Users/fangzeqiang/Downloads/Rapid_charging_points.gpkg")
```

```{r}
# charging_points %>%
#   names()
charging_points %>%
  nrow()
```

